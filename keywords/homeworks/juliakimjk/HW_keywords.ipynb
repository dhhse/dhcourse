{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from string import punctuation\n",
    "from pymystem3 import Mystem\n",
    "import operator\n",
    "from stop_words import get_stop_words\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Функция для извлечения ключевых биграмм из текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_analyzer(file):\n",
    "    m = Mystem()\n",
    "    with open(file, 'r', encoding=\"UTF-8\") as f:\n",
    "        text = f.read()\n",
    "    non_lemmatized = [token.strip(punctuation) for token in text.split() if token.isalnum()]\n",
    "    text_string = ' '.join(non_lemmatized)\n",
    "    lemmatized = m.lemmatize(text_string) #лемматизируем текст\n",
    "    lemmas = []\n",
    "    for lemma in lemmatized:\n",
    "        if lemma.isalnum():\n",
    "            lemmas.append(lemma) #избавляемся от остатков пунктуации\n",
    "    bigrams = [] #создаем список биграмм (из лемм)\n",
    "    for i in range(len(lemmas) - 1):\n",
    "        bigram = \"{} {}\".format(lemmas[i], lemmas[i+1])\n",
    "        bigrams.append(bigram)\n",
    "    bigram_dict = {} #считаем повторяющиеся биграммы и складываем в словарь\n",
    "    for bigram in bigrams:\n",
    "        n = bigrams.count(bigram)\n",
    "        bigram_dict[bigram] = n\n",
    "    sorted_dict = {}\n",
    "    stop_words = get_stop_words('ru')\n",
    "    for key, value in bigram_dict.items():\n",
    "        if key.split()[0] in stop_words or key.split()[1] in stop_words: #если хотя бы одно слово в биграмме есть в списке стоп-слов, то выбрасываем ее\n",
    "            pass\n",
    "        else:\n",
    "            sorted_dict[key] = value #если оба слова в биграмме не стоп-слова, то складываем их в новый словарь\n",
    "    sorted_counts = sorted(sorted_dict.items(), key=operator.itemgetter(1), reverse=True) #сортируем\n",
    "    number = dict(sorted_counts[:5]) #делаем срез из 5 самых частотных\n",
    "    print(number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Функция для подсчета частотности лемм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemma_counter(file):\n",
    "    m = Mystem()\n",
    "    with open(file, 'r', encoding=\"UTF-8\") as f:\n",
    "        text = f.read()\n",
    "    non_lemmatized = [token.strip(punctuation) for token in text.split() if token.isalnum()]\n",
    "    text_string = ' '.join(non_lemmatized)\n",
    "    lemmatized = m.lemmatize(text_string) #лемматизируем текст\n",
    "    lemmas = []\n",
    "    for lemma in lemmatized:\n",
    "        if lemma.isalnum():\n",
    "            lemmas.append(lemma) #избавляемся от остатков пунктуации\n",
    "    lemmas_dict = {}\n",
    "    for lemma in lemmas:\n",
    "        n = lemmas.count(lemma) #считаем частотность лемм в тексте\n",
    "        lemmas_dict[lemma] = n #и складываем их в словарь\n",
    "    sorted_dict = {}\n",
    "    stop_words = get_stop_words('ru')\n",
    "    for key, value in lemmas_dict.items():\n",
    "        if key in stop_words: #если лемма - это стоп-слово, то выкидываем ее\n",
    "            pass\n",
    "        else:\n",
    "            sorted_dict[key] = value #а если нет - то добавляем в словарь\n",
    "    sorted_counts = sorted(sorted_dict.items(), key=operator.itemgetter(1), reverse=True) #сортируем\n",
    "    number = dict(sorted_counts[:5]) #делаем срез из 5 самых частотных\n",
    "    print(number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Тестируем на случайных текстах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('sample_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.txt\n",
      "{'картина': 6, 'описание': 4, 'левитан': 3, 'сюжет': 3, 'любовь': 2}\n",
      "{'описание картина': 4, 'картина левитан': 2, 'автор использовать': 2, 'художник передвижник': 1, 'передвижник описание': 1}\n",
      "3.txt\n",
      "{'маленький': 3, 'белый': 3, 'картина': 2, 'корзухин': 2, 'комнатка': 2}\n",
      "{'описание картина': 1, 'картина корзухин': 1, 'корзухин описывать': 1, 'зритель представать': 1, 'представать маленький': 1}\n",
      "txt.txt\n",
      "{'картина': 22, 'свой': 8, 'изображать': 8, 'художник': 7, 'левитан': 7}\n",
      "{'описание картина': 5, 'картина левитан': 3, 'суриков описание': 2, 'картина европа': 2, 'европа суриков': 2}\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir():\n",
    "    print(os.path.basename(file)) #печатаем имя файла\n",
    "    lemma_counter(file) #печатаем самые частотные леммы\n",
    "    my_analyzer(file) #печатаем самые частотные биграммы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Тестируем на датасете russia_today_0.jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "with open(\"russia_today_0.jsonlines\", \"r\", encoding=\"UTF-8\") as read_file: #откроем файл и построчно считаем данные\n",
    "    for line in read_file:\n",
    "        data.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('data')\n",
    "os.chdir('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "for item in data:\n",
    "    with open('{}.txt'.format(i), 'w', encoding=\"UTF-8\") as fl: #запишем каждый текст в отдельный txt файл\n",
    "        fl.write(item['content'])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.txt\n",
      "{'турция': 23, 'турецкий': 17, 'сша': 12, 'американский': 11, 'санкция': 10}\n",
      "{'американский санкция': 3, 'вводить санкция': 3, 'фонд защита': 3, 'защита демократия': 3, 'президент турция': 2}\n",
      "10.txt\n",
      "{'власть': 11, 'мьянма': 9, 'гуманитарный': 8, 'мусульманин': 8, 'рохинджа': 6}\n",
      "{'бирманский власть': 4, 'прекращение огонь': 3, 'власть мьянма': 3, 'официальный представитель': 2, 'аун сан': 2}\n",
      "100.txt\n",
      "{'турнир': 20, 'сет': 14, 'победа': 13, 'четвертьфинал': 13, 'пробиваться': 12}\n",
      "{'турнир большой': 7, 'Australian Open': 6, 'ракетка планета': 5, 'январь 2018': 5, '22 январь': 4}\n",
      "101.txt\n",
      "{'музей': 11, 'российский': 5, 'институт': 5, 'археология': 5, 'малый': 4}\n",
      "{'институт археология': 5, 'малый николаевский': 4, 'николаевский дворец': 4, 'чудово монастырь': 4, 'археология российский': 4}\n",
      "102.txt\n",
      "{'трамп': 10, 'победа': 10, 'свой': 8, 'сша': 8, 'дональд': 7}\n",
      "{'дональд трамп': 6, 'южный корея': 2, '3 январь': 2, 'ким чен': 2, 'соединять штат': 2}\n",
      "103.txt\n",
      "{'ядерный': 15, 'корея': 13, 'испытание': 13, 'кндр': 12, 'северный': 11}\n",
      "{'северный корея': 8, 'ядерный испытание': 6, 'водородный бомба': 4, 'подземный толчок': 3, 'ядерный оружие': 3}\n",
      "104.txt\n",
      "{'украина': 14, 'американский': 9, 'продукт': 6, 'говориться': 5, 'доклад': 5}\n",
      "{'минсельхоз сша': 3, 'украина являться': 2, 'политический обстановка': 2, 'уровень коррупция': 2, 'американский бизнесмен': 2}\n",
      "105.txt\n",
      "{'мэннинг': 13, 'январь': 10, '2017': 10, '17': 8, 'челси': 7}\n",
      "{'январь 2017': 10, '17 январь': 6, '18 январь': 4, 'решение обама': 3, 'челси мэннинг': 3}\n",
      "106.txt\n",
      "{'свой': 9, 'команда': 7, 'становиться': 7, 'матч': 6, 'мяч': 6}\n",
      "{'становиться автор': 2, 'тур чемпионат': 1, 'чемпионат россия': 1, 'футбол получаться': 1, 'получаться усеченный': 1}\n",
      "107.txt\n",
      "{'олимпийский': 5, 'ксения': 5, 'ехать': 4, 'свой': 4, 'становиться': 4}\n",
      "{'евгения медведева': 1, 'медведева вновь': 1, 'вновь набирать': 1, 'набирать невероятный': 1, 'девушка количество': 1}\n",
      "108.txt\n",
      "{'белорусский': 10, 'президент': 8, 'свой': 8, 'белоруссия': 7, 'лукашенко': 7}\n",
      "{'президент белоруссия': 4, 'александр лукашенко': 4, 'белоруссия александр': 2, 'белорусский лидер': 2, 'повторять свой': 2}\n",
      "109.txt\n",
      "{'военный': 19, 'россия': 19, 'самолет': 17, 'сила': 16, 'российский': 14}\n",
      "{'ВКС россия': 6, 'военный авиация': 5, 'российский военный': 4, 'сила россия': 4, 'вооруженный сила': 4}\n",
      "11.txt\n",
      "{'трамп': 6, 'президент': 6, 'The': 4, 'помещать': 4, 'Daily': 4}\n",
      "{'президент сша': 3, 'The Economist': 2, 'дональд трамп': 2, 'Washington City': 2, 'City Paper': 2}\n",
      "110.txt\n",
      "{'шарапов': 8, 'свой': 8, 'кубок': 7, 'кремль': 7, 'мария': 7}\n",
      "{'кубок кремль': 7, 'октябрь 2017': 3, 'приезд мария': 2, 'одерживать победа': 2, '17 октябрь': 2}\n",
      "111.txt\n",
      "{'трамп': 10, 'свой': 7, 'дональд': 7, 'протест': 7, 'президент': 6}\n",
      "{'хиллари клинтон': 4, '8 ноябрь': 3, 'акция протест': 3, 'миллион американец': 2, 'итог президентский': 2}\n",
      "112.txt\n",
      "{'балл': 7, 'фигурный': 5, 'чемпионат': 4, 'европа': 4, 'становиться': 4}\n",
      "{'чемпионат европа': 3, 'фигурный катание': 3, 'произвольный танец': 3, 'танцевальный праздник': 1, 'болельщик вечерний': 1}\n",
      "113.txt\n",
      "{'россия': 16, 'флот': 12, 'российский': 11, 'экономический': 8, 'сила': 8}\n",
      "{'российский флот': 5, 'государственный политика': 3, 'заявлять RT': 3, 'число атомный': 3, 'атомный подводный': 3}\n",
      "114.txt\n",
      "{'санкция': 19, 'белоруссия': 18, 'отношение': 8, 'канада': 6, 'экономический': 6}\n",
      "{'отношение белоруссия': 3, 'белорусский чиновник': 2, 'александр лукашенко': 2, 'снятие санкция': 2, 'экономический план': 2}\n",
      "115.txt\n",
      "{'оон': 9, 'сша': 6, 'кндр': 6, 'совбез': 6, 'резолюция': 5}\n",
      "{'совбез оон': 4, 'проект резолюция': 3, 'сша совбез': 3, 'северный корея': 3, 'оон одобрять': 2}\n",
      "116.txt\n",
      "{'кндр': 9, 'северный': 6, 'резолюция': 5, 'китай': 5, 'корея': 4}\n",
      "{'северный корея': 3, 'министр иностранный': 3, 'иностранный дело': 3, 'заявление комитет': 2, 'совбез оон': 2}\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir()[:20]: #делаем срез из 20 файлов\n",
    "    print(os.path.basename(file)) #печатаем имя файла\n",
    "    lemma_counter(file) #печатаем самые частотные леммы\n",
    "    my_analyzer(file) #печатаем самые частотные биграммы"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
