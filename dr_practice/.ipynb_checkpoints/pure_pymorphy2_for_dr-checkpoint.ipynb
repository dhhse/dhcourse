{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание: сделать лемматизацию \"Преступления и наказания\" с помощью PyMophy2 \n",
    "\n",
    "1. напечатать 100 первых слов \n",
    "2. напечатать 100 самых частотных слов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Откроем файл в питоне"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# откроем файл в питоне\n",
    "path_to_file = 'Dostoevsky_PrestuplenieINakazanie.txt'\n",
    "prest_i_nak = open (path_to_file, 'r')\n",
    "prest_i_nak_kak_stroka = prest_i_nak.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Токенизируем готовым токенизатором"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# если у вас еще нет nltk, установите его:\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# импортируем из нлтк готовый токенизатор\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Преступление',\n",
       " 'и',\n",
       " 'наказание',\n",
       " 'Роман',\n",
       " 'в',\n",
       " 'шести',\n",
       " 'частях',\n",
       " 'с',\n",
       " 'эпилогом',\n",
       " 'Часть',\n",
       " 'первая',\n",
       " 'I',\n",
       " 'В',\n",
       " 'начале',\n",
       " 'июля',\n",
       " ',',\n",
       " 'в',\n",
       " 'чрезвычайно',\n",
       " 'жаркое',\n",
       " 'время']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# токенизируем\n",
    "prest_i_nak_nltk_tokenized = word_tokenize (prest_i_nak_kak_stroka)\n",
    "prest_i_nak_nltk_tokenized [:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Лемматизируем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Если не установлен pymorphy2\n",
    "!pip install pymorphy2\n",
    "## можете попробовать также быструю версию pip install pymorphy2[fast], но тут возможны проблемы "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymorphy2 import MorphAnalyzer\n",
    "morph = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_pres_i_nak = []\n",
    "for word in prest_i_nak_nltk_tokenized:\n",
    "    rezultat_analiza = morph.parse(word)\n",
    "    naibolee_veroyantniy_razbor = rezultat_analiza[0] ## почему мы берем первый разбор? \n",
    "    ## см.в этом месте: https://pymorphy2.readthedocs.io/en/latest/user/guide.html#select-correct\n",
    "    lemma = naibolee_veroyantniy_razbor.normal_form\n",
    "    lemmatized_pres_i_nak.append(lemma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Работает это, правда, долго, секунд 20-30 :( "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['преступление', 'и', 'наказание', 'роман', 'в', 'шесть', 'часть', 'с', 'эпилог', 'часть', 'один', 'i', 'в', 'начало', 'июль', ',', 'в', 'чрезвычайно', 'жаркое', 'время']\n"
     ]
    }
   ],
   "source": [
    "print (lemmatized_pres_i_nak[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 100 самых частотных можно сделать с помощью FreqDist \n",
    "from nltk import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 25337),\n",
       " ('и', 8451),\n",
       " ('.', 8198),\n",
       " ('--', 6073),\n",
       " ('он', 5176),\n",
       " ('в', 3955),\n",
       " ('не', 3779),\n",
       " ('я', 3466),\n",
       " ('что', 3452),\n",
       " ('!', 3265),\n",
       " ('быть', 2480),\n",
       " ('на', 2407),\n",
       " ('?', 2245),\n",
       " ('с', 2215),\n",
       " ('...', 2097),\n",
       " ('весь', 2003),\n",
       " ('она', 1988),\n",
       " ('вы', 1824),\n",
       " ('это', 1821),\n",
       " ('а', 1775)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FreqDist(lemmatized_pres_i_nak).most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Если не нравятся запятые и пробелы в списке частотностей -- можно их убрать в какой-то момент"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('и', 8451),\n",
       " ('он', 5176),\n",
       " ('в', 3955),\n",
       " ('не', 3779),\n",
       " ('я', 3466),\n",
       " ('что', 3452),\n",
       " ('быть', 2480),\n",
       " ('на', 2407),\n",
       " ('с', 2215),\n",
       " ('весь', 2003),\n",
       " ('она', 1988),\n",
       " ('вы', 1824),\n",
       " ('это', 1821),\n",
       " ('а', 1775),\n",
       " ('как', 1622),\n",
       " ('так', 1172),\n",
       " ('но', 1155),\n",
       " ('же', 1130),\n",
       " ('да', 1055),\n",
       " ('ты', 1019)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_lemmatized_pres_i_nak = [] #создадим новый список, куда положим только те слова, которые хотим видеть\n",
    "for word in lemmatized_pres_i_nak:\n",
    "    if word not in [',','!',';','?','.',' ',':', '&','--','...','-']:\n",
    "        clean_lemmatized_pres_i_nak.append(word)\n",
    "FreqDist(clean_lemmatized_pres_i_nak).most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('и', 8451),\n",
       " ('он', 5176),\n",
       " ('в', 3955),\n",
       " ('не', 3779),\n",
       " ('я', 3466),\n",
       " ('что', 3452),\n",
       " ('быть', 2480),\n",
       " ('на', 2407),\n",
       " ('с', 2215),\n",
       " ('весь', 2003),\n",
       " ('она', 1988),\n",
       " ('вы', 1824),\n",
       " ('это', 1821),\n",
       " ('а', 1775),\n",
       " ('как', 1622),\n",
       " ('так', 1172),\n",
       " ('но', 1155),\n",
       " ('же', 1130),\n",
       " ('да', 1055),\n",
       " ('ты', 1019)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## То же самое быстрее можно сделать так, без создания доп список :\n",
    "FreqDist(word for word in lemmatized_pres_i_nak if word not in [',','!',';','?','.',' ',':', '&','--','...','-']).most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('и', 8451),\n",
       " ('он', 5176),\n",
       " ('в', 3955),\n",
       " ('не', 3779),\n",
       " ('я', 3466),\n",
       " ('что', 3452),\n",
       " ('быть', 2480),\n",
       " ('на', 2407),\n",
       " ('с', 2215),\n",
       " ('весь', 2003),\n",
       " ('она', 1988),\n",
       " ('вы', 1824),\n",
       " ('это', 1821),\n",
       " ('а', 1775),\n",
       " ('как', 1622),\n",
       " ('так', 1172),\n",
       " ('но', 1155),\n",
       " ('же', 1130),\n",
       " ('да', 1055),\n",
       " ('ты', 1019)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## или так\n",
    "for word in lemmatized_pres_i_nak:\n",
    "    if word in [',','!',';','?','.',' ',':', '&','--','...','-']:\n",
    "        lemmatized_pres_i_nak.remove(word)\n",
    "FreqDist(lemmatized_pres_i_nak).most_common(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
